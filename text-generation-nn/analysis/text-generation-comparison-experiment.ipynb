{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation neural network\n",
    "\n",
    "This neural network generates new pet names by first training a neural network on pet names from Seattle pet license data. The training runs very quickly by distributing the training work across multiple computers with GPUs in Saturn Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries for doing the Saturn Cloud parallel work\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dask_pytorch_ddp import data, dispatch, results\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "from distributed.worker import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_names_raw = pd.read_csv(\"https://raw.githubusercontent.com/saturncloud/saturn-cloud-examples/master/text-generation-nn/seattle_pet_licenses.csv\")\n",
    "pet_names = pet_names_raw[\"Animal's Name\"].tolist()\n",
    "# Our list of characters, where * represents blank and + represents stop\n",
    "characters = list(\"*+abcdefghijklmnopqrstuvwxyz-. \")\n",
    "\n",
    "str_len = 8\n",
    "num_epochs = 7\n",
    "lstm_size = 128\n",
    "lstm_layers = 4\n",
    "\n",
    "\n",
    "def format_training_data(pet_names):\n",
    "    def get_substrings(in_str):\n",
    "        in_str = in_str.lower() + \"+\"\n",
    "        res = [in_str[0: j] for j in range(1, len(in_str) + 1)]\n",
    "        return res\n",
    "    pattern = re.compile(\"^[ \\\\.\\\\-a-zA-Z]*$\")\n",
    "    pet_names_filtered = [name for name in pet_names if isinstance(name, str) and not name.isspace() and pattern.match(name)]\n",
    "    pet_names_expanded = [get_substrings(name) for name in  pet_names_filtered]\n",
    "    pet_names_expanded = [item for sublist in pet_names_expanded for item in sublist]\n",
    "    pet_names_characters = [list(name) for name in pet_names_expanded]\n",
    "    pet_names_padded = [name[-(str_len + 1):] for name in pet_names_characters]\n",
    "    pet_names_padded = [list((str_len + 1- len(characters)) * \"*\") + characters for characters in pet_names_padded]\n",
    "    pet_names_numeric = [[characters.index(char) for char in name] for name in pet_names_padded]\n",
    "\n",
    "    # the final x and y data\n",
    "    y = torch.tensor([name[1:] for name in pet_names_numeric])\n",
    "    x = torch.tensor([name[:-1] for name in pet_names_numeric])\n",
    "    x = torch.nn.functional.one_hot(x, num_classes = len(characters)).float()\n",
    "    return x, y\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=len(characters),\n",
    "            hidden_size=lstm_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.fc = nn.Linear(lstm_size, len(characters))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, state = self.lstm(x)\n",
    "        logits = self.fc(output)\n",
    "        return logits\n",
    "\n",
    "    def init_state(self, custom_batch_size=None):\n",
    "        if custom_batch_size is None:\n",
    "            custom_batch_size = batch_size\n",
    "        return (torch.zeros(lstm_layers, custom_batch_size, lstm_size),\n",
    "                torch.zeros(lstm_layers, custom_batch_size, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class OurDataset(Dataset):\n",
    "    def __init__(self, pet_names):\n",
    "        self.x, self.y = format_training_data(pet_names)\n",
    "        self.permute()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.permutation[idx]\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def permute(self):\n",
    "        self.permutation = torch.randperm(len(self.x))\n",
    "        \n",
    "# pet_names_raw = pd.read_csv(\"https://raw.githubusercontent.com/saturncloud/saturn-cloud-examples/master/text-generation-nn/seattle_pet_licenses.csv\")\n",
    "# pet_names = pet_names_raw[\"Animal's Name\"].tolist()        \n",
    "# loader = DataLoader(OurDataset(pet_names), batch_size=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training function\n",
    "# when this is run it saved the model output after each epoch (overwriting the previous one)\n",
    "# If multiple computers are training the model, they'll each save to the same place\n",
    "\n",
    "\n",
    "def train():\n",
    "    worker_rank = int(dist.get_rank())\n",
    "    logger.info(f\"Worker {worker_rank} - beginning\")\n",
    "\n",
    "    # x, y = format_training_data(pet_names)\n",
    "    dataset = OurDataset(pet_names)\n",
    "    sampler = DistributedSampler(dataset)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    worker_rank = int(dist.get_rank())\n",
    "    device = torch.device(0)\n",
    "    \n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    device_ids = [0]\n",
    "    model = DDP(model, device_ids=device_ids)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001*learning_rate_multiplier)\n",
    "    \n",
    "    num_batches = len(loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.info(f\"Worker {worker_rank} - {datetime.datetime.now().isoformat()} - Beginning epoch {epoch}\")\n",
    "        sampler.set_epoch(epoch)\n",
    "            \n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # batch_y_pred, (state_h, state_c) = model(batch_x, (state_h, state_c))\n",
    "            batch_y_pred = model(batch_x)\n",
    "            # state_h = state_h.detach()\n",
    "            # state_c = state_c.detach()\n",
    "            # batch_y_pred = model(batch_x)\n",
    "            loss = criterion(batch_y_pred.transpose(1, 2), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            logger.info(f\"Worker {worker_rank} - {datetime.datetime.now().isoformat()} - epoch {epoch} - batch {i} - batch complete - loss {loss.item()}\")\n",
    "        # store metrics while the model is training\n",
    "        current_time = datetime.datetime.now().isoformat()\n",
    "        rh.submit_result(\n",
    "            f\"logs/data_{worker_rank}_{epoch}_{current_time}.json\", \n",
    "            json.dumps({'loss': loss.item(),\n",
    "                        'elapsed_time': (datetime.datetime.now() - training_start_time).total_seconds(),\n",
    "                        'epoch': epoch,\n",
    "                        'worker': worker_rank})\n",
    "        )\n",
    "        #### I think there might be a bug with rh concurrency by having these two calls next to each other so I'm putting a sleep here\n",
    "        # save the model at the end of each epoch\n",
    "        rh.submit_result(f\"model.pkl\", pickle.dumps(model.state_dict()))\n",
    "        dataset.permute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16384\n",
    "learning_rate_multiplier = 1\n",
    "num_workers = 3\n",
    "\n",
    "key = uuid.uuid4().hex\n",
    "rh = results.DaskResultsHandler(key)\n",
    "cluster = SaturnCluster()\n",
    "cluster.scale(num_workers)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the parallel job, and use process_results to save the output\n",
    "# client.restart()\n",
    "training_start_time = datetime.datetime.now()\n",
    "futures = dispatch.run(client, train)\n",
    "rh.process_results(f\"/home/jovyan/training/{datetime.datetime.now().isoformat()}/\", futures, raise_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size, num_workers, learning_rate_multiplier\n",
    "parameters = [\n",
    "    (16384, 3, 1),\n",
    "    (int(16384/3), 3, 1),\n",
    "    (16384, 3, 3),\n",
    "    (int(16384/3), 3, 3),\n",
    "    (16384, 1, 1),\n",
    "    (int(16384/3), 1, 1),\n",
    "    (16384, 1, 3),\n",
    "    (int(16384/3), 1, 3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:05:34.348255 - Running training for batch=16384 num_workers=3 learning_rate_multiplier=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}, 'tcp://10.0.13.144:43293': {'status': 'repeat'}, 'tcp://10.0.3.61:33135': {'status': 'repeat'}}\n",
      "ERROR:root:Timed out trying to connect to 'tcp://d-jnoli-neural-net-test-3a7c9e5679eb46bd834b2094f4113405.main-namespace:8786' after 10 s: Timed out trying to connect to 'tcp://d-jnoli-neural-net-test-3a7c9e5679eb46bd834b2094f4113405.main-namespace:8786' after 10 s: connect() didn't finish in time\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 322, in connect\n",
      "    _raise(error)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 275, in _raise\n",
      "    raise IOError(msg)\n",
      "OSError: Timed out trying to connect to 'tcp://d-jnoli-neural-net-test-3a7c9e5679eb46bd834b2094f4113405.main-namespace:8786' after 10 s: connect() didn't finish in time\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_pytorch_ddp/results.py\", line 57, in _get_results\n",
      "    fut.result()\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    result = self.client.sync(self._result, callback_timeout=timeout, raiseit=False)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py\", line 833, in sync\n",
      "    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils.py\", line 340, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils.py\", line 324, in f\n",
      "    result[0] = yield future\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/tornado/gen.py\", line 762, in run\n",
      "    value = future.result()\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py\", line 247, in _result\n",
      "    result = await self.client._gather([self])\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py\", line 1880, in _gather\n",
      "    response = await future\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py\", line 1931, in _gather_remote\n",
      "    response = await retry_operation(self.scheduler.gather, keys=keys)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils_comm.py\", line 390, in retry_operation\n",
      "    operation=operation,\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils_comm.py\", line 370, in retry\n",
      "    return await coro()\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/core.py\", line 880, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/core.py\", line 1035, in connect\n",
      "    **self.connection_args,\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 334, in connect\n",
      "    _raise(error)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 275, in _raise\n",
      "    raise IOError(msg)\n",
      "OSError: Timed out trying to connect to 'tcp://d-jnoli-neural-net-test-3a7c9e5679eb46bd834b2094f4113405.main-namespace:8786' after 10 s: Timed out trying to connect to 'tcp://d-jnoli-neural-net-test-3a7c9e5679eb46bd834b2094f4113405.main-namespace:8786' after 10 s: connect() didn't finish in time\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-3577cba997d083f190a0eefacf569bc4': ('tcp://10.0.3.61:33135',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:15:27.685761 - Running training for batch=5461 num_workers=3 learning_rate_multiplier=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}, 'tcp://10.0.13.144:43293': {'status': 'repeat'}, 'tcp://10.0.3.61:33135': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-eb213cd6e784ce29c7a8abf21c288df3': ('tcp://10.0.0.125:42207',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:26:14.089030 - Running training for batch=16384 num_workers=3 learning_rate_multiplier=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}, 'tcp://10.0.13.144:43293': {'status': 'repeat'}, 'tcp://10.0.3.61:33135': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-eb213cd6e784ce29c7a8abf21c288df3': ('tcp://10.0.0.125:42207',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:36:08.396415 - Running training for batch=5461 num_workers=3 learning_rate_multiplier=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}, 'tcp://10.0.13.144:43293': {'status': 'repeat'}, 'tcp://10.0.3.61:33135': {'status': 'repeat'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished coro=<connect.<locals>._() done, defined at /srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py:288> exception=CommClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 297, in _\n",
      "    handshake = await asyncio.wait_for(comm.read(), 1)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/asyncio/tasks.py\", line 435, in wait_for\n",
      "    await waiter\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 304, in _\n",
      "    raise CommClosedError() from e\n",
      "distributed.comm.core.CommClosedError\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished coro=<connect.<locals>._() done, defined at /srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py:288> exception=CommClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 297, in _\n",
      "    handshake = await asyncio.wait_for(comm.read(), 1)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/asyncio/tasks.py\", line 435, in wait_for\n",
      "    await waiter\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 304, in _\n",
      "    raise CommClosedError() from e\n",
      "distributed.comm.core.CommClosedError\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished coro=<connect.<locals>._() done, defined at /srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py:288> exception=CommClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 297, in _\n",
      "    handshake = await asyncio.wait_for(comm.read(), 1)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/asyncio/tasks.py\", line 435, in wait_for\n",
      "    await waiter\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 304, in _\n",
      "    raise CommClosedError() from e\n",
      "distributed.comm.core.CommClosedError\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished coro=<connect.<locals>._() done, defined at /srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py:288> exception=CommClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 297, in _\n",
      "    handshake = await asyncio.wait_for(comm.read(), 1)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/asyncio/tasks.py\", line 435, in wait_for\n",
      "    await waiter\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 304, in _\n",
      "    raise CommClosedError() from e\n",
      "distributed.comm.core.CommClosedError\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished coro=<connect.<locals>._() done, defined at /srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py:288> exception=CommClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 297, in _\n",
      "    handshake = await asyncio.wait_for(comm.read(), 1)\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/asyncio/tasks.py\", line 435, in wait_for\n",
      "    await waiter\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/comm/core.py\", line 304, in _\n",
      "    raise CommClosedError() from e\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:45:29.938927 - Running training for batch=16384 num_workers=3 learning_rate_multiplier=0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}, 'tcp://10.0.13.144:43293': {'status': 'repeat'}, 'tcp://10.0.3.61:33135': {'status': 'repeat'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:50:55.012705 - Running training for batch=16384 num_workers=1 learning_rate_multiplier=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}, 'tcp://10.0.13.144:43293': {'status': 'repeat'}, 'tcp://10.0.3.61:33135': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-936f95bee4bf75d35a0e9149cf3914a6': ('tcp://10.0.0.125:42207',)}\n",
      "INFO:dask-saturn:Cluster is ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:54:06.893501 - Running training for batch=5461 num_workers=1 learning_rate_multiplier=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-936f95bee4bf75d35a0e9149cf3914a6': ('tcp://10.0.0.125:42207',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T20:57:16.530829 - Running training for batch=16384 num_workers=1 learning_rate_multiplier=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-936f95bee4bf75d35a0e9149cf3914a6': ('tcp://10.0.0.125:42207',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T21:00:26.870718 - Running training for batch=5461 num_workers=1 learning_rate_multiplier=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-936f95bee4bf75d35a0e9149cf3914a6': ('tcp://10.0.0.125:42207',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18T21:03:37.096368 - Running training for batch=16384 num_workers=1 learning_rate_multiplier=0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.125:42207': {'status': 'repeat'}}\n",
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'dispatch_with_ddp-936f95bee4bf75d35a0e9149cf3914a6': ('tcp://10.0.0.125:42207',)}\n"
     ]
    }
   ],
   "source": [
    "for batch_size, num_workers, learning_rate_multiplier in parameters:\n",
    "    print(f\"{datetime.datetime.now().isoformat()} - Running training for batch={batch_size} num_workers={num_workers} learning_rate_multiplier={learning_rate_multiplier}\")\n",
    "    training_start_time = datetime.datetime.now()\n",
    "    key = uuid.uuid4().hex\n",
    "    rh = results.DaskResultsHandler(key)\n",
    "    cluster = SaturnCluster()\n",
    "    cluster.scale(num_workers)\n",
    "    client = Client(cluster)\n",
    "    futures = dispatch.run(client, train)\n",
    "    rh.process_results(f\"/home/jovyan/training-comparison/{comparison_start_time.isoformat()}/batch={batch_size}&num_workers={num_workers}&learning_rate_multiplier={learning_rate_multiplier}/\", futures, raise_errors=False)\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
