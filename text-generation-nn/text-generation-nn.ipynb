{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation neural network\n",
    "\n",
    "This neural network generates new pet names by first training a neural network on pet names from Seattle pet license data. The training runs very quickly by distributing the training work across multiple computers with GPUs in Saturn Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries for doing the Saturn Cloud parallel work\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from dask_pytorch_ddp import data, dispatch, results\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "from distributed.worker import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk creates the X and y matrices to train a model on and the model structure itself. The 3-dimensional X matrix represents (data point, place in text sequence, character [1-hot encoded]). The 2-dimensional y matrix represents (data point, character to predict)\n",
    "\n",
    "# Our list of characters, where * represents blank and + represents stop\n",
    "characters = list(\"*+abcdefghijklmnopqrstuvwxyz-. \")\n",
    "\n",
    "str_len = 8\n",
    "num_epochs = 100\n",
    "batch_size = 16384\n",
    "print_every = 16384\n",
    "lstm_size = 128\n",
    "lstm_layers = 4\n",
    "\n",
    "pet_names_raw = pd.read_csv(\"https://raw.githubusercontent.com/saturncloud/saturn-cloud-examples/master/text-generation-nn/seattle_pet_licenses.csv\")\n",
    "\n",
    "pet_names = pet_names_raw[\"Animal's Name\"].tolist()\n",
    "\n",
    "def get_substrings(in_str):\n",
    "    in_str = in_str.lower() + \"+\"\n",
    "    res = [in_str[0: j] for j in range(1, len(in_str) + 1)]\n",
    "    return res\n",
    "\n",
    "pattern = re.compile(\"^[ \\\\.\\\\-a-zA-Z]*$\")\n",
    "pet_names_filtered = [name for name in pet_names if isinstance(name, str) and not name.isspace() and pattern.match(name)]\n",
    "pet_names_expanded = [get_substrings(name) for name in  pet_names_filtered]\n",
    "pet_names_expanded = [item for sublist in pet_names_expanded for item in sublist]\n",
    "pet_names_characters = [list(name) for name in pet_names_expanded]\n",
    "pet_names_padded = [name[-(str_len + 1):] for name in pet_names_characters]\n",
    "pet_names_padded = [list((str_len + 1- len(characters)) * \"*\") + characters for characters in pet_names_padded]\n",
    "pet_names_numeric = [[characters.index(char) for char in name] for name in pet_names_padded]\n",
    "\n",
    "# the final x and y data\n",
    "y = torch.tensor([name[1:] for name in pet_names_numeric])\n",
    "x = torch.tensor([name[:-1] for name in pet_names_numeric])\n",
    "x = torch.nn.functional.one_hot(x, num_classes = len(characters)).float()\n",
    "\n",
    "# the lstm model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=len(characters),\n",
    "            hidden_size=lstm_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.fc = nn.Linear(lstm_size, len(characters))\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        output, state = self.lstm(x, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, custom_batch_size=None):\n",
    "        if custom_batch_size is None:\n",
    "            custom_batch_size = batch_size\n",
    "        return (torch.zeros(lstm_layers, custom_batch_size, lstm_size),\n",
    "                torch.zeros(lstm_layers, custom_batch_size, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{'tcp://10.0.0.118:41631': {'status': 'repeat'}, 'tcp://10.0.0.67:36669': {'status': 'repeat'}, 'tcp://10.0.27.147:41551': {'status': 'repeat'}}\n"
     ]
    }
   ],
   "source": [
    "# This starts the parallel cluster in Saturn\n",
    "key = uuid.uuid4().hex\n",
    "rh = results.DaskResultsHandler(key)\n",
    "cluster = SaturnCluster()\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training function\n",
    "# when this is run it saved the model output after each epoch (overwriting the previous one)\n",
    "# If multiple computers are training the model, they'll each save to the same place\n",
    "def train():\n",
    "    # send the model to the computer the code is running on\n",
    "    worker_rank = int(dist.get_rank())\n",
    "    logger.info(f\"Worker - {worker_rank} - starting up\")\n",
    "    orig_model = Model()\n",
    "    device = torch.device(0)\n",
    "    orig_model = orig_model.to(device)\n",
    "    device_ids = [0]\n",
    "    model = DDP(orig_model, device_ids=device_ids)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    logger.info(f\"Worker - {worker_rank} - setup complete\")\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.info(f\"Worker - {worker_rank} - Epoch {epoch} - beginning\")\n",
    "        state_h, state_c = orig_model.init_state()\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        permutation = torch.randperm(x.size()[0])\n",
    "        for i in range(0,x.size()[0] - (x.size()[0] % batch_size), batch_size):\n",
    "            logger.info(f\"Worker - {worker_rank} - Epoch {epoch} - Batch {round(i/batch_size)} - beginning\")\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = x[indices], y[indices]\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            batch_y_pred, (state_h, state_c) = model(batch_x, (state_h, state_c))\n",
    "            loss = criterion(batch_y_pred.transpose(1, 2), batch_y)\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # store metrics while the model is training\n",
    "            if (i / batch_size) % print_every == 0:\n",
    "                rh.submit_result(\n",
    "                    f\"worker/{worker_rank}/data-{datetime.datetime.now().isoformat()}.json\", \n",
    "                    json.dumps({'loss': loss.item(),\n",
    "                                'epoch': epoch,\n",
    "                                'pct': (i/x.size()[0]),\n",
    "                                'iter': (i/batch_size), \n",
    "                                'total': (x.size()[0])/batch_size,\n",
    "                                'worker': worker_rank})\n",
    "                )\n",
    "            logger.info(f\"Worker - {worker_rank} - Epoch {epoch} - Batch {round(i/batch_size)} - Loss {loss.item()}\")\n",
    "        # save the model at the end of each epoch\n",
    "        rh.submit_result(f\"model.pkl\", pickle.dumps(model.state_dict()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d5258f6aa8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/jovyan/training/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_pytorch_ddp/results.py\u001b[0m in \u001b[0;36mprocess_results\u001b[0;34m(self, prefix, futures, raise_errors)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mraise_errors\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mjobs\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meither\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0man\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_pytorch_ddp/results.py\u001b[0m in \u001b[0;36m_get_results\u001b[0;34m(self, futures, raise_errors)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_sub_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_pytorch_ddp/results.py\u001b[0m in \u001b[0;36m_get_all\u001b[0;34m(cls, sub)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/pubsub.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_timedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ident\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             return sync(\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             )\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the parallel job, and use process_results to save the output\n",
    "client.restart()\n",
    "futures = dispatch.run(client, train)\n",
    "rh.process_results(\"/home/jovyan/training/\", futures, raise_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating names with a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(lstm_model, init_state, characters, str_len):\n",
    "    in_progress_name = []\n",
    "    next_letter = \"\"\n",
    "    state_h, state_c = init_state(1)\n",
    "    while(not next_letter == \"+\" and len(in_progress_name) < 30):\n",
    "        # prep the data to run in the model again\n",
    "        in_progress_name_padded = in_progress_name[-str_len:]\n",
    "        in_progress_name_padded = list((str_len - len(in_progress_name_padded)) * \"*\") + in_progress_name_padded\n",
    "        in_progress_name_numeric = [characters.index(char) for char in in_progress_name_padded]\n",
    "        in_progress_name_tensor = torch.tensor(in_progress_name_numeric)\n",
    "        in_progress_name_tensor = torch.nn.functional.one_hot(in_progress_name_tensor, num_classes = len(characters)).float()\n",
    "        in_progress_name_tensor = torch.unsqueeze(in_progress_name_tensor, 0)\n",
    "        # get the probabilities of each possible next character by running the model\n",
    "        with torch.no_grad():\n",
    "            next_letter_probabilities, (state_h, state_c) = lstm_model(in_progress_name_tensor, (state_h, state_c))\n",
    "        next_letter_probabilities = next_letter_probabilities[0,-1,:]\n",
    "        next_letter_probabilities = torch.nn.functional.softmax(next_letter_probabilities, dim=0).detach().cpu().numpy()\n",
    "        next_letter_probabilities = next_letter_probabilities[1:]\n",
    "        next_letter_probabilities = [p/sum(next_letter_probabilities) for p in next_letter_probabilities]\n",
    "        # determine what the actual letter is\n",
    "        next_letter = characters[np.random.choice(len(characters)-1, p=next_letter_probabilities) + 1]\n",
    "        if(next_letter != \"+\"):\n",
    "            # if the next character isn't stop add the latest generated character to the name and continue\n",
    "            in_progress_name.append(next_letter)\n",
    "  # turn the list of characters into a single string\n",
    "    raw_name = \"\".join(in_progress_name)\n",
    "    # capitalize the first letter of each word\n",
    "    capitalized_name = raw_name.title()\n",
    "    return capitalized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and the trained parameters\n",
    "model_state = pickle.load(open(\"/home/jovyan/training/model.pkl\", \"rb\"))\n",
    "model = Model()\n",
    "model_parallel = torch.nn.DataParallel(model).cuda()  \n",
    "model_parallel.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beeger Len Laccencterny', 'Ctontor', 'Krin', 'Smurkle', 'Monsu', 'Jascenfa', 'Tipake', 'Yooru', 'Prade', 'Roea', 'Munashhetearlavy Radmasb', 'Jakis', 'Scogenea', 'Tassin', 'Boanne', 'Koqrey', 'Gusker', 'Ganlie', 'Chacgly', 'Kolonc', 'Cacdy', 'Laley', 'Hajisa', 'Kar Don', 'Mingly Wicsy Salri Goddimtons', 'Feora', 'Kalry', 'Zoa', 'Burac Ah-Srassy Nucchhel', 'Grue', 'Bezbynant Gortedde', 'Kaziy', 'Shouu', 'Raffekla', 'Mikim', 'Jodpe', 'Muitn', 'Markor', 'Echee', 'Iski', 'Yick', 'Kissia', 'Bryrpy', 'Jatar Hecsrurnes', 'Maidie', 'Rramd', 'Cine', 'Judde', 'Joszar']\n"
     ]
    }
   ],
   "source": [
    "# Generate 50 names then filter out existing ones\n",
    "generated_names = [generate_name(model_parallel, model.init_state, characters, str_len) for i in range(0,50)]\n",
    "generated_names = [name for name in generated_names if name not in pet_names]\n",
    "print(generated_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
