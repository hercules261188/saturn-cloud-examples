{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation neural network\n",
    "\n",
    "This neural network generates new pet names by first training a neural network on pet names from Seattle pet license data. The training runs very quickly by distributing the training work across multiple computers with GPUs in Saturn Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries for doing the Saturn Cloud parallel work\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from dask_pytorch_ddp import data, dispatch, results\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk creates the X and y matrices to train a model on and the model structure itself. The 3-dimensional X matrix represents (data point, place in text sequence, character [1-hot encoded]). The 2-dimensional y matrix represents (data point, character to predict)\n",
    "\n",
    "# Our list of characters, where * represents blank and + represents stop\n",
    "characters = list(\"*+abcdefghijklmnopqrstuvwxyz-. \")\n",
    "\n",
    "str_len = 8\n",
    "num_epochs = 100\n",
    "batch_size = 16384\n",
    "print_every = 16384\n",
    "lstm_size = 128\n",
    "lstm_layers = 4\n",
    "\n",
    "pet_names_raw = pd.read_csv(\"https://raw.githubusercontent.com/nolis-llc/pet-names/master/seattle_pet_licenses.csv\")\n",
    "\n",
    "pet_names = pet_names_raw[\"Animal's Name\"].tolist()\n",
    "\n",
    "def get_substrings(in_str):\n",
    "    in_str = in_str.lower() + \"+\"\n",
    "    res = [in_str[0: j] for j in range(1, len(in_str) + 1)]\n",
    "    return res\n",
    "\n",
    "pattern = re.compile(\"^[ \\\\.\\\\-a-zA-Z]*$\")\n",
    "pet_names_filtered = [name for name in pet_names if isinstance(name, str) and not name.isspace() and pattern.match(name)]\n",
    "pet_names_expanded = [get_substrings(name) for name in  pet_names_filtered]\n",
    "pet_names_expanded = [item for sublist in pet_names_expanded for item in sublist]\n",
    "pet_names_characters = [list(name) for name in pet_names_expanded]\n",
    "pet_names_padded = [name[-(str_len + 1):] for name in pet_names_characters]\n",
    "pet_names_padded = [list((str_len + 1- len(characters)) * \"*\") + characters for characters in pet_names_padded]\n",
    "pet_names_numeric = [[characters.index(char) for char in name] for name in pet_names_padded]\n",
    "\n",
    "# the final x and y data\n",
    "y = torch.tensor([name[1:] for name in pet_names_numeric])\n",
    "x = torch.tensor([name[:-1] for name in pet_names_numeric])\n",
    "x = torch.nn.functional.one_hot(x, num_classes = len(characters)).float()\n",
    "\n",
    "# the lstm model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=len(characters),\n",
    "            hidden_size=lstm_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.fc = nn.Linear(lstm_size, len(characters))\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        output, state = self.lstm(x, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, custom_batch_size=None):\n",
    "        if custom_batch_size is None:\n",
    "            custom_batch_size = batch_size\n",
    "        return (torch.zeros(lstm_layers, custom_batch_size, lstm_size),\n",
    "                torch.zeros(lstm_layers, custom_batch_size, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 17:35:20] INFO - dask-saturn | Cluster is ready\n",
      "[2021-02-11 17:35:20] INFO - dask-saturn | Registering default plugins\n",
      "[2021-02-11 17:35:21] INFO - dask-saturn | {'tcp://10.0.13.15:39573': {'status': 'OK'}, 'tcp://10.0.17.139:42451': {'status': 'OK'}, 'tcp://10.0.8.117:40397': {'status': 'OK'}}\n"
     ]
    }
   ],
   "source": [
    "# This starts the parallel cluster in Saturn\n",
    "key = uuid.uuid4().hex\n",
    "rh = results.DaskResultsHandler(key)\n",
    "cluster = SaturnCluster()\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training function\n",
    "# when this is run it saved the model output after each epoch (overwriting the previous one)\n",
    "# If multiple computers are training the model, they'll each save to the same place\n",
    "def train():\n",
    "    # send the model to the computer the code is running on\n",
    "    worker_rank = int(dist.get_rank())\n",
    "    orig_model = Model()\n",
    "    device = torch.device(0)\n",
    "    orig_model = orig_model.to(device)\n",
    "    device_ids = [0]\n",
    "    model = DDP(orig_model, device_ids=device_ids)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(num_epochs):\n",
    "        state_h, state_c = orig_model.init_state()\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        permutation = torch.randperm(x.size()[0])\n",
    "        for i in range(0,x.size()[0] - (x.size()[0] % batch_size), batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = x[indices], y[indices]\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            batch_y_pred, (state_h, state_c) = model(batch_x, (state_h, state_c))\n",
    "            loss = criterion(batch_y_pred.transpose(1, 2), batch_y)\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # store metrics while the model is training\n",
    "            if (i / batch_size) % print_every == 0:\n",
    "                rh.submit_result(\n",
    "                    f\"worker/{worker_rank}/data-{datetime.datetime.now().isoformat()}.json\", \n",
    "                    json.dumps({'loss': loss.item(),\n",
    "                                'epoch': epoch,\n",
    "                                'pct': (i/x.size()[0]),\n",
    "                                'iter': (i/batch_size), \n",
    "                                'total': (x.size()[0])/batch_size,\n",
    "                                'worker': worker_rank})\n",
    "                )\n",
    "        # save the model at the end of each epoch\n",
    "        rh.submit_result(f\"model.pkl\", pickle.dumps(model.state_dict()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the parallel job, and use process_results to save the output\n",
    "client.restart()\n",
    "futures = dispatch.run(client, train)\n",
    "rh.process_results(\"/home/jovyan/training/\", futures, raise_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating names with a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(lstm_model, init_state, characters, str_len):\n",
    "    in_progress_name = []\n",
    "    next_letter = \"\"\n",
    "    state_h, state_c = init_state(1)\n",
    "    while(not next_letter == \"+\" and len(in_progress_name) < 30):\n",
    "        # prep the data to run in the model again\n",
    "        in_progress_name_padded = in_progress_name[-str_len:]\n",
    "        in_progress_name_padded = list((str_len - len(in_progress_name_padded)) * \"*\") + in_progress_name_padded\n",
    "        in_progress_name_numeric = [characters.index(char) for char in in_progress_name_padded]\n",
    "        in_progress_name_tensor = torch.tensor(in_progress_name_numeric)\n",
    "        in_progress_name_tensor = torch.nn.functional.one_hot(in_progress_name_tensor, num_classes = len(characters)).float()\n",
    "        in_progress_name_tensor = torch.unsqueeze(in_progress_name_tensor, 0)\n",
    "        # get the probabilities of each possible next character by running the model\n",
    "        with torch.no_grad():\n",
    "            next_letter_probabilities, (state_h, state_c) = lstm_model(in_progress_name_tensor, (state_h, state_c))\n",
    "        next_letter_probabilities = next_letter_probabilities[0,-1,:]\n",
    "        next_letter_probabilities = torch.nn.functional.softmax(next_letter_probabilities, dim=0).detach().cpu().numpy()\n",
    "        next_letter_probabilities = next_letter_probabilities[1:]\n",
    "        next_letter_probabilities = [p/sum(next_letter_probabilities) for p in next_letter_probabilities]\n",
    "        # determine what the actual letter is\n",
    "        next_letter = characters[np.random.choice(len(characters)-1, p=next_letter_probabilities) + 1]\n",
    "        if(next_letter != \"+\"):\n",
    "            # if the next character isn't stop add the latest generated character to the name and continue\n",
    "            in_progress_name.append(next_letter)\n",
    "  # turn the list of characters into a single string\n",
    "    raw_name = \"\".join(in_progress_name)\n",
    "    # capitalize the first letter of each word\n",
    "    capitalized_name = raw_name.title()\n",
    "    return capitalized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and the trained parameters\n",
    "model_state = pickle.load(open(\"/home/jovyan/training/model.pkl\", \"rb\"))\n",
    "model = Model()\n",
    "model_parallel = torch.nn.DataParallel(model).cuda()  \n",
    "model_parallel.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beeger Len Laccencterny', 'Ctontor', 'Krin', 'Smurkle', 'Monsu', 'Jascenfa', 'Tipake', 'Yooru', 'Prade', 'Roea', 'Munashhetearlavy Radmasb', 'Jakis', 'Scogenea', 'Tassin', 'Boanne', 'Koqrey', 'Gusker', 'Ganlie', 'Chacgly', 'Kolonc', 'Cacdy', 'Laley', 'Hajisa', 'Kar Don', 'Mingly Wicsy Salri Goddimtons', 'Feora', 'Kalry', 'Zoa', 'Burac Ah-Srassy Nucchhel', 'Grue', 'Bezbynant Gortedde', 'Kaziy', 'Shouu', 'Raffekla', 'Mikim', 'Jodpe', 'Muitn', 'Markor', 'Echee', 'Iski', 'Yick', 'Kissia', 'Bryrpy', 'Jatar Hecsrurnes', 'Maidie', 'Rramd', 'Cine', 'Judde', 'Joszar']\n"
     ]
    }
   ],
   "source": [
    "# Generate 20 names\n",
    "generated_names = [generate_name(model_parallel, model.init_state, characters, str_len) for i in range(0,50)]\n",
    "generated_names = [name for name in generated_names if name not in pet_names]\n",
    "print(generated_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
